{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hello = tf.constant(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.Tensor"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(hello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'hello world'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(hello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.constant(3)\n",
    "y = tf.constant(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First TensorFlow\n",
      "Addition 5\n",
      "Substraction 1\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print('First TensorFlow')\n",
    "    print('Addition',sess.run(x+y))\n",
    "    print('Substraction', sess.run(x-y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.int32)\n",
    "y = tf.placeholder(tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "addi = tf.add(x,y)\n",
    "subi = tf.subtract(x,y)\n",
    "mul = tf.multiply(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = {x: 30, y:15}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placeholder\n",
      "Addition 45\n",
      "Substraction 15\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print('Placeholder')\n",
    "    print('Addition', sess.run(addi, feed_dict = d))\n",
    "    print('Substraction', sess.run(subi, feed_dict = d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.array([[5.0,5.0]])\n",
    "y = np.array([[2.0],[3.0]])\n",
    "z = np.array([[2,3,1],[4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mat1 = tf.constant(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mat2 = tf.constant(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrixMul = tf.matmul(mat1,mat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MatMul:0\", shape=(1, 1), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(matrixMul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix multiplication [[ 25.]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print('Matrix multiplication',sess.run(matrixMul))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.contrib.learn.python.learn.datasets.base.Datasets"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist.train.images)\n",
    "mnist.train.images[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = mnist.train.images[2].reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0d5b231d68>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0d5b2e8b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer number of features\n",
    "n_hidden_2 = 256 # 2nd layer number of features\n",
    "n_input = 784 # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "n_samples = mnist.train.num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multilayer_perceptron(x, weights, biases):\n",
    "    '''\n",
    "    x : Place Holder for Data Input\n",
    "    weights: Dictionary of weights\n",
    "    biases: Dicitionary of biases\n",
    "    '''\n",
    "    \n",
    "    # First Hidden layer with RELU activation\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    \n",
    "    # Second Hidden layer with RELU activation\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    \n",
    "    # Last Output layer with linear activation\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "pred = multilayer_perceptron(x, weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = pred, logits = y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No gradients provided for any variable, check your graph for ops that do not support gradients, between variables ['Tensor(\"Variable/read:0\", shape=(784, 256), dtype=float32)', 'Tensor(\"Variable_1/read:0\", shape=(256, 256), dtype=float32)', 'Tensor(\"Variable_2/read:0\", shape=(256, 10), dtype=float32)', 'Tensor(\"Variable_3/read:0\", shape=(256,), dtype=float32)', 'Tensor(\"Variable_4/read:0\", shape=(256,), dtype=float32)', 'Tensor(\"Variable_5/read:0\", shape=(10,), dtype=float32)', 'Tensor(\"Variable_6/read:0\", shape=(256,), dtype=float32)', 'Tensor(\"Variable_7/read:0\", shape=(256,), dtype=float32)', 'Tensor(\"Variable_8/read:0\", shape=(10,), dtype=float32)', 'Tensor(\"Variable_9/read:0\", shape=(784, 256), dtype=float32)', 'Tensor(\"Variable_10/read:0\", shape=(256, 256), dtype=float32)', 'Tensor(\"Variable_11/read:0\", shape=(256, 10), dtype=float32)', 'Tensor(\"Variable_12/read:0\", shape=(256,), dtype=float32)', 'Tensor(\"Variable_13/read:0\", shape=(256,), dtype=float32)', 'Tensor(\"Variable_14/read:0\", shape=(10,), dtype=float32)', 'Tensor(\"Variable_15/read:0\", shape=(256,), dtype=float32)', 'Tensor(\"Variable_16/read:0\", shape=(256,), dtype=float32)', 'Tensor(\"Variable_17/read:0\", shape=(10,), dtype=float32)'] and loss Tensor(\"Mean:0\", shape=(), dtype=float32).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-5e8da1634f64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/abhimanyu/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, global_step, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, name, grad_loss)\u001b[0m\n\u001b[1;32m    293\u001b[0m           \u001b[0;34m\"No gradients provided for any variable, check your graph for ops\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m           \u001b[0;34m\" that do not support gradients, between variables %s and loss %s.\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m           ([str(v) for _, v in grads_and_vars], loss))\n\u001b[0m\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     return self.apply_gradients(grads_and_vars, global_step=global_step,\n",
      "\u001b[0;31mValueError\u001b[0m: No gradients provided for any variable, check your graph for ops that do not support gradients, between variables ['Tensor(\"Variable/read:0\", shape=(784, 256), dtype=float32)', 'Tensor(\"Variable_1/read:0\", shape=(256, 256), dtype=float32)', 'Tensor(\"Variable_2/read:0\", shape=(256, 10), dtype=float32)', 'Tensor(\"Variable_3/read:0\", shape=(256,), dtype=float32)', 'Tensor(\"Variable_4/read:0\", shape=(256,), dtype=float32)', 'Tensor(\"Variable_5/read:0\", shape=(10,), dtype=float32)', 'Tensor(\"Variable_6/read:0\", shape=(256,), dtype=float32)', 'Tensor(\"Variable_7/read:0\", shape=(256,), dtype=float32)', 'Tensor(\"Variable_8/read:0\", shape=(10,), dtype=float32)', 'Tensor(\"Variable_9/read:0\", shape=(784, 256), dtype=float32)', 'Tensor(\"Variable_10/read:0\", shape=(256, 256), dtype=float32)', 'Tensor(\"Variable_11/read:0\", shape=(256, 10), dtype=float32)', 'Tensor(\"Variable_12/read:0\", shape=(256,), dtype=float32)', 'Tensor(\"Variable_13/read:0\", shape=(256,), dtype=float32)', 'Tensor(\"Variable_14/read:0\", shape=(10,), dtype=float32)', 'Tensor(\"Variable_15/read:0\", shape=(256,), dtype=float32)', 'Tensor(\"Variable_16/read:0\", shape=(256,), dtype=float32)', 'Tensor(\"Variable_17/read:0\", shape=(10,), dtype=float32)'] and loss Tensor(\"Mean:0\", shape=(), dtype=float32)."
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-75-0f50547c66e8>:1: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xsamp,ysamp = mnist.train.next_batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0d5afe2048>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8ANBEX4gqP8HdDtbXOQ5PmoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0d5b061a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(Xsamp.reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(ysamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optimizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-199036cf7a43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# Returns a tuple, but we only need 'c' the cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# So we set an underscore as a \"throwaway\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# Compute average loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'optimizer' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# Intialize all the variables\n",
    "sess.run(init)\n",
    "\n",
    "# Training Epochs\n",
    "# Essentially the max amount of loops possible before we stop\n",
    "# May stop earlier if cost/loss limit was set\n",
    "for epoch in range(training_epochs):\n",
    "\n",
    "    # Start with cost = 0.0\n",
    "    avg_cost = 0.0\n",
    "\n",
    "    # Convert total number of batches to integer\n",
    "    total_batch = int(n_samples/batch_size)\n",
    "\n",
    "    # Loop over all batches\n",
    "    for i in range(total_batch):\n",
    "\n",
    "        # Grab the next batch of training data and labels\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "\n",
    "        # Feed dictionary for optimization and loss value\n",
    "        # Returns a tuple, but we only need 'c' the cost\n",
    "        # So we set an underscore as a \"throwaway\"\n",
    "        _, c = sess.run([optimizer, cost], feed_dict={x: batch_x, y: batch_y})\n",
    "\n",
    "        # Compute average loss\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print(\"Epoch: {} cost={:.4f}\".format(epoch+1,avg_cost))\n",
    "\n",
    "print(\"Model has completed {} Epochs of Training\".format(training_epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
